#端口
server:
  port: 8888

#数据库连接
spring:
  application:
    name: tail
  datasource:
    url: jdbc:mysql://127.0.0.1:3306/trial?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
    username: root
    password: root
    driver-class-name: com.mysql.cj.jdbc.Driver
    type: com.alibaba.druid.pool.DruidDataSource
    # 数据源其他配置
    initialSize: 5
    minIdle: 5
    maxActive: 20
    maxWait: 60000
    timeBetweenEvictionRunsMillis: 60000
    minEvictableIdleTimeMillis: 300000
    validationQuery: SELECT 1 FROM DUAL
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    poolPreparedStatements: true
  #redis
  redis:
    # Redis数据库索引（默认为0）
    database: 0
    # Redis服务器地址,端口
    host: 121.199.164.16
    port: 6379
    # Redis服务器连接密码（默认为空）
    password:
    jedis:
      pool:
        # 连接池最大连接数（使用负值表示没有限制）
        max-active: 20
        # 连接池最大阻塞等待时间（使用负值表示没有限制）
        max-wait:
        # 连接池中的最大空闲连接
        max-idle: 10
        min-idle: 1
    # 连接超时时间（毫秒）
    timeout: 1000ms
  #kafka
  kafka:
      bootstrap-servers: 121.199.164.16:9092
      # producer 生产者
      producer:
        # 重试次数
        retries: 0
        # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
        # acks=0 ： 生产者在成功写入消息之前不会等待任何来自服务器的响应。
        # acks=1 ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应。
        # acks=all ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
        acks: -1
        batch-size: 16384 # 批量大小
        buffer-memory: 33554432 # 生产端缓冲区大小
        key-serializer: org.apache.kafka.common.serialization.StringSerializer
        value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # consumer消费者
      consumer:
        # 默认的消费组ID
        group-id: test-consumer-group
        # 是否自动提交offset
        enable-auto-commit: false
        # 当kafka中没有初始offset或offset超出范围时将自动重置offset;
        # earliest:重置为分区中最小的offset;
        # latest:重置为分区中最新的offset(消费分区中新产生的数据);
        # none:只要有一个分区不存在已提交的offset,就抛出异常;
        key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
# cloud中的zk配置
  cloud:
    zookeeper:
      connect-string: 121.199.164.16:2181

# mybitis
mybatis:
  mapperLocations: classpath:mapper/*.xml
  #开启sql打印
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
#log
logging:
  level:
    root: info
    com.bestvike: debug
    org.springframework.security: warn
    # 默认日志文件名
#    file: log
    # 默认日志路径
#     path: ./log
#     logback.xml路径，默认为classpath:logback.xml
#     config: ./logback.xml
rocketmq:
  name-server: 121.199.164.16:9876
  producer:
    group: test-group
    # 超时时长 默认值
    send-message-timeout: 3000
    # 失败重试 默认值
    retry-times-when-send-failed: 2
